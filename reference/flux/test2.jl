using ReverseDiff
using Statistics

logsoftmax(y) = y.-log.(sum(exp.(y), dims=1))
logitcrossentropy(ŷ, y) = mean(.-sum(y .* logsoftmax(ŷ); dims=1))
crossentropy(ŷ, y) = -sum(y .* log.(ŷ))

lossfun = crossentropy

W = [
    0.9032294842032307 1.4580230482780379 0.9310737880870507 1.1078463467814603 0.9148034098230938;
    0.11668451330809364 0.22821957601479792 1.7219137174748527 0.50884994302868 0.46319956459103007;
    1.8935648128511766 0.9149075179410003 0.5904856093147604 1.1312243565957947 0.7803309323918235;
    0.49135525694170146 0.3300399360866784 0.22673982804736076 1.590391961842889 0.5721860571075313;
    0.891552228329739 0.7915383581003806 0.5371599284764134 0.22198555796012634 0.23241707056348793;
    0.22886890334681814 0.21341787856291763 0.7490686531318762 0.7185754431704935 0.8726286623779024;
    1.1562322112758119 2.109483277071983 1.209482561668428 1.9545604047295333 0.5242536937822103;
    1.5155150335659924 0.9407211049689689 0.9224087705945953 1.2013672245406082 0.31311150641510643;
    0.9213104293760906 0.0299181242563318 0.731878698017706 1.021678835876467 0.9093530941420519;
    0.21335406646523716 1.064224607244219 0.7303425396061004 0.1751511905658525 1.3936092070796675;
    0.9468201683854216 1.6914066026373635 0.20533720641846576 0.25583214386307485 1.5072767964876896;
    1.111122722720771 0.6070038304951009 0.2544244415583391 1.1849201012991477 0.32010980719644705;
    0.4575974148040482 0.1640054823968387 0.46241113281414264 0.2875765220950689 0.283116690902816;
    1.687603194498139 0.8457670485226456 2.1167917563888663 1.122888164838142 0.5292648475973878;
    0.5124010448525874 1.7656762271568327 0.1833707842698142 0.39038171637593544 1.2530040989828652;
    1.5434777877637214 2.5877598854408874 0.292590332753358 0.2661670132881214 0.5562683547179444;
    0.4939106000569548 0.06421637865406256 1.2457654742036028 1.2014087629756702 1.3108846702846528;
    0.3687249423335804 2.2461988122693843 0.8765342199675517 0.6416327045366876 0.5301017038940709;
    0.07209062200390745 1.8281939078892828 0.5151602322277371 2.900678772089583 1.1550754460222896;
    0.6988334283674431 0.5786021382871562 0.6786387647135722 2.410415564128154 2.0579203641852986
]
x = [
    0.044818005017491114,
    0.933353287277165,
    0.5805599818745412, 
    0.5468807556603925,
    0.05129481188265768
]

net(W) = lossfun(tanh.(W*x), ones(20))
ReverseDiff.gradient(net, W)